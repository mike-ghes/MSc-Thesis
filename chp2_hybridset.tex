\chapter{Hybrid Set Theory}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% INTRODUCTION
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The motivation behind hybrid sets and functions can be traced to wanting a better approach to piecewise functions
and closely related to that is a more generalized notion of a partition.
In general, we assume a piecewise function $f : P \to X$ will take the form:
\begin{equation}
	\label{eq_fP}
	f(x) = 
	     \begin{cases}
	       f_1(x) & x \in P_1 \\
	       f_2(x) & x \in P_2 \\ 
	       \vdots & \vdots \\
	       f_n(x) & x \in P_n
	     \end{cases}
\end{equation}
where the set $\{ P _ i \}$ is a partition of $P$, the domain of $f$.
and each function $f_i: P_i \to X$ is defined over a corresponding part of $P$. 
We assume that $f_i$ is fully defined on $P_i$ (\emph{total}) but may be partial on $P$ .
Frequently these partitions are not expressed explicitly as sets but rather as conditions.
For example, the absolute value function is far more commonly written out as
\begin{equation*}
	\abs(x) = \begin{cases} -x & x < 0 \\ x & x \geq 0 \end{cases}
	\;\;\;\;\;\;\;\;\;\text{rather than}\;\;\;\;\;\;\;\;\;
	\abs(x) = 
	\begin{cases}
		-x & \{x \;|\; x \in \mathbb{R} \wedge x < 0\}  \\ 
		x & \{x \;|\; x \in \mathbb{R} \wedge x \geq 0 \}
	\end{cases}
\end{equation*}
but using conditions rather than the sets they define can be seen as just a shorthand. 


One thing that should be noted is that sometimes there are additional conjuncts bundled into a condition.
As pieces of a partition, the sets generated must be disjoint so we must ensure these conditions are mutually exclusive.
A common heuristic is to treat these conditions as a series of cascading \emph{else-if} statements.
For example \emph{Maple}'s \texttt{piecewise} function:
\begin{quote}
	\texttt{piecewise(cond\_1, f\_1, cond\_2, f\_2, \ldots, cond\_n, f\_n, f\_otherwise)} 
\end{quote}	
will evaluate each \texttt{cond\_1} in order and when one evaluates to true, the corresponding \texttt{f\_i} is then evaluated.
Finally if all of \texttt{cond\_i} evaluate to false then \texttt{f\_otherwise} is used.
Hence the partitions corresponding to each \texttt{cond\_i} is \emph{not} just $\{ x \;|\; \texttt{cond\_i}(x) \}$
but instead the set where \texttt{cond\_i} is true and \emph{all preceding} conditions are also false.


Although the notation used in (\ref{eq_fP}) is fine for piecewise functions with only a few terms such as $\abs$,
it quickly becomes unwieldy when one wants to add more pieces.
So instead we will use the \emph{join} of disjoint function \emph{restrictions}.
\begin{definition}
	Given a function $f:X \to Y$ and any subset of the domain $Z \subset X$, 
	the \textbf{restriction of $\boldsymbol{f}$ to $\boldsymbol{Z}$} is the function $f|_Z : Z \to Y$, 
	such that $f|_Z(x) = f(x)$ for all $x \in Z$.
\end{definition}


There are several ways which one could define a join operator; specifically how one deals with intersections.
One could favor the first function as Maple does, but we will take the stance that the intersection is poorly defined.
\begin{definition}
	Define $\fjoin$, the \textbf{join} of two functions, $f$ and $g$ by:
	\begin{equation}
	\label{def:fjoin}
		f \fjoin g =  
		\left\{
	     		\begin{array}{lr}
	       		f(x) & \text{if } g(x) = \bot \\
	       		g(x) & \text{if } f(x) = \bot \\
	       		\bot & otherwise
	     		\end{array}
	   	\right.
	\end{equation}
\end{definition}
Where the bottom element $\bot$ denotes that the function is undefined.
As such if $f:X \to Y$ and $g:S \to T$ then the join will be defined not on the union of $X$ and $S$ but on their 
\emph{symmetric difference}.
Together these definitions allow us to re-write the piecewise function in (\ref{eq_fP}) as:
\begin{equation*}
	f = \restrict{f}{P_1} \fjoin \restrict{f}{P_2} \fjoin \ldots \fjoin \restrict{f}{P_n}
\end{equation*}
Normally, the join operator $\fjoin$ is not associative and so omitting parentheses could lead to poorly defined expressions.
However, when all support sets are pairwise disjoint, then $\fjoin$ is associative.


Now consider arithmetic of two piecewise functions. Let $f$ and $g$ be two piecewise functions
$f = \left(\restrict{f_1}{P_1} \fjoin \restrict{f_2}{P_2} \fjoin \restrict{f_3}{P_3} \right)$ 
and $g= \left( \restrict{g_1}{Q_1} \fjoin \restrict{g_2}{Q_2} \right)$.
To compute the sum $f+g$ we need to consider each possible intersection of partitions of $P$ and partitions of $Q$.
In this case, the result is generally a piecewise function with 6 terms:
\begin{align*}
	(f+g) = \;
	&\restrict{(f_1+g_1)}{P_1 \cap Q_1} 
		\;\fjoin\; \restrict{(f_1+g_2)}{P_1 \cap Q_2} 
		\;\fjoin\; \restrict{(f_1+g_3)}{P_1 \cap Q_3}\notag\\
	&\restrict{(f_2+g_1)}{P_2 \cap Q_1} 
	 	\;\fjoin\; \restrict{(f_2+g_2)}{P_2 \cap Q_2} 
	 	\;\fjoin\; \restrict{(f_2+g_3)}{P_2 \cap Q_3}
\end{align*}
In specific cases, some terms may be eliminated as the corresponding intersection is empty. 
In general, assuming no degenerate intersections, 
the sum of an ``$n$-piece'' function and ``$m$-piece'' function will give a piecewise function with $n \times m$ pieces.
This becomes compounded when dealing with more piecewise functions. 
The sum of $b$ functions each with $n$ pieces results in $b^n$ cases making computation unrealistic 
in all but the smallest cases.


Another perspective to take is to first find a \emph{common refinement} of ${P=\{P_i\}_{i\in I}}$ 
and ${Q=\{Q_j\}_{j\in J}}$. In the above example we selected the refinement:
\begin{equation*}
	R=\Big\{\;
		(P_1 \cap Q_1),\;(P_2 \cap Q_1),\;(P_3 \cap Q_1),\;
		(P_1 \cap Q_2),\;(P_2 \cap Q_2),\;(P_3 \cap Q_2) \;
	\Big\}
\end{equation*}
That is, for each $P_i$ in the partition $P$, there is a subset of $R$ which will partition $P_i$ 
(namely $P_i = \{ (P_i \cap Q_1), (P_i \cap Q_2) \}$ and so $R$ is a \emph{refinement} of $P$.
Similarly $R$ also a refinement of $Q$ and so we say it is a \emph{common refinement} of $P$ and $Q$.


Finding common refinements gives a large increase in the number of terms required, 
in part, due to a restrictive view of partitions.
Conceptually, what one wishes out of a partition is a family of subsets which will ``sum'' up to the original.
With Boolean sets, some additional constraints are imposed as we don't have a very good notion of subtraction.
However, with more general structures, we can construct true inverse sets to allow for algebraic cancellations.
Following the development of \cite{carette2010}, over this chapter we will consider such generalized partitions 
and the structures to support them.
We will also see how this allows for us to eliminate the multiplicative increase in terms when flattening an expression
containing the sum or product of piecewise functions.





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Hybrid Sets
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Hybrid Sets}


We consider \emph{hybrid sets} which are a generalization of multi-sets.
One can view usual Boolean sets as an indicator function on the universe
which maps each member element to 1 and each non-member to 0.
A \emph{multi-set} (or \emph{bag}) extends this by allowing multiple copies of the same element.
The indicator function of a multi-set would therefore range over $\mathbb{N}_0$, the set of non-negative integers.
Hybrid sets take this one step further allowing for an element to occur \emph{negatively many} times 
as an indicator function over the integers.


\begin{definition}
	Let $U$ be a set, then any function $U \to \mathbb{Z}$ is called a \textbf{hybrid set}.
	We denote the collection of all hybrid sets over an underlining set $U$ by $\hsetover[U]$.
\end{definition}


By universe, we just mean a usual Boolean set that \emph{contains everything we may be interested in}.
This is admittedly vague but we will rarely be interested in everything in the universe or its exact size.
It is simply a compact way for us to talk about ``everything else''.
But we will need some notation to make functions resemble sets.


\begin{definition}
	Let $H$ be a hybrid set. 
	Then we say that $H(x)$ is the \textbf{multiplicity} of the element $x$. 
	We write, $x \in^n H$ if $H(x)=n$. 
	Furthermore we will use $x \in H$ to denote $H(x)\neq 0$ (or equivalently, $x \in^n H$ for $n\neq 0$).
	Conversely, $x \notin H$ denotes $x \in^0 H$ or $H(x)=0$.
	The symbol $\emptyset$ will be used to denote the empty hybrid set for which all elements have multiplicity 0.
	Finally the \textbf{support of a hybrid set} is the (non-hybrid) set $\supp\;H$,
	where $x \in \supp\;H$ if and only if $x \in H$
\end{definition}


We will use the notation:
\begin{equation*}
	H = \hset{x_1^{m_1}, x_2^{m_2},\ldots}
\end{equation*}
to describe the hybrid set $H$ where the element $x_i$ has multiplicity $m_i$. 
We allow for repetitions in $\{ x_i \}$ but interpret the overall multiplicity of an element $x_i$ as 
the sum of multiplicities among copies. 
For example, $H=\hset{a^1, a^1, b^{-2}, a^3, b^1} = \hset{a^5, b^{-1}}$. 
The latter will generally be preferred as all $a$'s and $b$'s have been collected together.
Such a writing in which $x_i \neq x_j$ for all $i \neq j$ is referred to as a \textbf{normalized form} of a hybrid set. 


Boolean sets use the operations $\cup$ union, $\cap$ intersection, and $\setminus$ complementation.
These correspond to the Boolean point-wise $\vee$ \texttt{OR}, $\wedge$ \texttt{AND}, and $\neg$ \texttt{NOT} 
operations. That is, for two sets $A$ and $B$, then $(A \cup B)(x) = A(x) \vee B(x)$.
One \emph{could} extend these for hybrid sets using point-wise min and max on multiplicities as in
\cite{blizard1988, blizard1990, girish2012multiset, singh2011complementation}
but this is not very natural.
Rather, our primitive hybrid set operations should derive from our primitive point-wise operators.
When dealing with hybrid sets with multiplicities over the integers, we have the ring $(\mathbb{Z}, +, \times)$.
Thus we will define $\oplus$, $\ominus$, and $\otimes$ by point-wise $+$, $-$, and $\times$ respectively.


\begin{definition}
	For any two hybrid sets $A$ and $B$ over a common universe $U$, 
	we define the operations $\oplus, \ominus, \otimes : \mathbb{Z}^U \times \mathbb{Z}^U \to \mathbb{Z}^U$ 
	such that for all $x \in U$:
	\begin{align}
		(A \oplus B)(x) 	&= A(x) + B(x) \\
		(A \ominus B)(x) 	&= A(x) - B(x) \\
		(A \otimes B)(x) 	&= A(x) \cdot B(x)
	\end{align}
	We also define, $\ominus A$ as $\emptyset \ominus A$ and for $c \in \mathbb{Z}$:
	\begin{equation}
		(cA)(x) = c \cdot A(x)
	\end{equation}
\end{definition}


\begin{definition}
	We say $\boldsymbol{A}$ \textbf{and} $\boldsymbol{B}$ \textbf{are disjoint} if and only if $A \otimes B = \emptyset$
\end{definition}
For Boolean sets $A$ and $B$, disjointness would be defined by $A \cap B = \emptyset$.
If we consider these Boolean sets as simply hybrid sets with multiplicity 0 or 1 then the operations $\cap$ and $\otimes$
identically correspond to element-wise $\texttt{AND}$.


From these definitions, we can use hybrid sets to model various objects that would traditionally be described otherwise. 
For example, any positive rational number can be represented as a hybrid set over the primes.
\begin{equation*}
	(\mathbb{Z}^\mathbb{P}, \oplus) \simeq (\mathbb{Q}_+,\times)
\end{equation*}
For a positive rational number $a/b$, both $a$ and $b$ being integers will have a prime decomposition: 
$a=(p_1^{m_1}\cdot p_2^{m_2} \cdot \ldots)$ and $b=(q_1^{n_1} \cdot q_2^{n_2} \cdot \ldots)$
then there is the group isomorphism $f$ given by:
\begin{equation*}
	f(a/b) = \hset{p_1^{m_1}, p_2^{m_2}, \ldots} \ominus \hset{q_1^{n_1}, q_2^{n_2}, \ldots}
\end{equation*}
Furthermore, we have the equivalence $ca/cb = a/b$ for free by writing the hybrid set in normalized form
(e.g. $2/4 = \hset{2^1, 2^{-2}} = \hset{2^{-1}} = 1/2$).
One could also think of the roots and asymptotes of a rational polynomial as a hybrid set over the underlying ring:
\begin{equation*}
	\frac{(x-2)}{(x-1)^2(x+1)} \;=\; \hset{ 2^1, 1^{-2}, -1^{-1} }
\end{equation*}
Depending on the context, a negative multiplicity could take many different meanings.
Rather than attach a single rigid concept, we will keep this flexibly abstract sometimes.
In these examples we used the multiplicity as an exponent in other cases it is more aptly a coefficient  or as orientation.


All Boolean sets can be trivially converted to hybrid sets.
For a set $X$, this is done simply by taking $H(x)=1$ if $x \in X$ and $H(x)=0$ if $x \notin X$.
We will often perform this conversion silently by applying hybrid set operators to Boolean sets.
The reverse conversion: the reduction of a hybrid set to a Boolean set is not always possible.


\begin{definition}
	Given a hybrid set $H$ over universe $U$, 
	if for all $x \in U$ $H(x)=1$ or $H(x)=0$ then we say that \textbf{$\boldsymbol{H(x)}$ is reducible}.
	If $H$ is reducible then we denote the \textbf{reduction of $\boldsymbol{H}$} by $\mathcal{R}(H)$ 
	as the (non-hybrid) set over $U$ with the same membership.  
\end{definition}


In Boolean set theory, a partition of $X$ is a collection of subsets of $X$ such that $X$ is a disjoint union of the subsets.
When dealing with hybrid sets we no longer have (or rather choose not to use) union but use point-wise sum instead.
For disjoint, reducible hybrid sets, point-wise sum and union agree but we will be even more accommodating 
and allow for \emph{any} family of sets which sum to a hybrid set to be a (generalized) partition.


\begin{definition}
	A \textbf{generalized partition $\boldsymbol{P}$ of a hybrid set $\boldsymbol{H(x)}$} is a family of hybrid sets
	${P=\{P_i \}_{i=1}^n}$ such that:
	\begin{equation}
		H = P_1 \oplus P_2 \oplus \ldots \oplus P_n
	\end{equation}
	We say that \textbf{$\boldsymbol{P}$ is a strict partition of $\boldsymbol{H}$} if 
	$P_i$ and $P_j$ are disjoint when $i \neq j$.
\end{definition}


If a set $H$ is reducible, then strict generalized partitions will correspond to the usual notion of a partition.
A traditional partition will be a disjoint cover of $H$ and for disjoint reducible sets, point-wise sum and union agree.
Hence $\bigcup_i P_i = \bigoplus_i P_i$. 
Conversely, if $H$ is reducible and the sum of disjoint hybrid sets, then $P_i$ must all be reducible as well.


This does not hold for a non-strict partition of a reducible hybrid set.
Consider the interval $[0,1]$ as a hybrid set (that is, $H(x)=1$ if $0 \leq x \leq 1$ and $H(x)=0$ otherwise).
Then $P = \big\{\; [0,2], \;\ominus (1,2] \; \big\}$ is a generalized partition of $H$. 
A generalized partition of a reducible set is strict if and only if each generalized partition is reducible.





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Hybrid Functions
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Hybrid Functions}
\label{sec:HybridFunction}


A function is typically defined as a mapping from elements of one set to another set.
We will consider functions which have hybrid sets as their domains (but still map to Boolean sets) 
which we will call \emph{hybrid functions}.
We will define hybrid functions as the collection of all pairs $(x,f(x))$ (i.e. the \emph{graph of the function} $f$).


\begin{definition}
	For two sets $S$ and $T$, a hybrid set over their Cartesian product $S \times T$ is called a 
	\textbf{hybrid (binary) relation between $\boldsymbol{S}$ and $\boldsymbol{T}$}.
	We denote the set of all such hybrid relations by $\mathbb{Z}^{S \times T}$. 
	A \textbf{hybrid function from $\boldsymbol{S}$ to $\boldsymbol{T}$} is 
	a hybrid relation $H$ between $S$ and $T$ such that $(x,y) \in H$ and $(x,z) \in H$ implies $y=z$.
	We denote the set of all such hybrid functions by $\mathbb{Z}^{S \to T}$.
\end{definition}


Again we will need some notation for this to be more usable.
We would like to think of a hybrid function not as a mapping from a hybrid set to a Boolean set but rather as
a function between two Boolean sets and integer multiplicity attached to the mapping (the ``arrow'' itself).
In this way we partially separate the traditional function and the multiplicity function (given as a hybrid set) and view a
hybrid function as their combined object.
Formally, given a hybrid set $H$ over $U$ and a function $f:B \to S$ be a function where $B \subseteq U$ and $S$ a set.
Then we denote by $f^H$ the hybrid function from $B$ to $S$ defined by:
\begin{equation}
	\label{eqn:hfunc}
	f^H := \bigoplus_{x \in B} H(x) \hset{ (x, f(x) )^1 }
\end{equation}


There is little literature or established use for hybrid functions;
their primary use to us will be as something that we can turn back into traditional functions.
So as with hybrid sets, we would like a notion of reducibility.


\begin{definition}
	If $H$ is a reducible hybrid set, then \textbf{$\boldsymbol{f^H}$ is a reducible hybrid function}. 
	Additionally, if $f^H$ is reducible, we extend $\mathcal{R}$ by:
	\begin{equation}
		\mathcal{R}(f^H)(x) = \restrict{f}{\mathcal{R}(H)}(x)
	\end{equation}
\end{definition}


Since $\mathcal{R}(H)$ only exists if $H(x)$ is everywhere 0 or 1; 
$\mathcal{R}(f^H)$ only makes sense when $f^H$ is reducible.
Assuming that we end up with a reducible function, 
hybrid functions will make an excellent primitives to construct piecewise functions.
Earlier we used the \emph{join of functions} to construct piecewise functions from \emph{restricted functions}.
The join operator for two hybrid functions is quite trivially defined.

 
\begin{definition}
	The \textbf{join}, $f^F \hjoin g^G$ of two hybrid functions $f^F$ and $g^G$ is 
	the hybrid relation given by their point-wise sum.
	\begin{equation} \label{def:hjoin}
		f^F \hjoin g^G = f^F \oplus g^G
	\end{equation}
\end{definition}


However, we will immediately dispense with using $\hjoin$ altogether and simply use $\oplus$ 
in order to prevent confusion between hybrid functional join (e.g. $f^F \oplus g^G$) and 
traditional functional join (e.g. $\restrict{f}{F} \fjoin \restrict{g}{G}$).
It is important to note that the join operator is closed under hybrid relations but not under hybrid functions.
For any two hybrid \emph{functions} the result will be a hybrid \emph{relation} 
but not necessarily another hybrid function.
As with traditional functional join, we must still be wary of overlapping regions
 but non-disjoint hybrid domains are not nearly as ``dangerous''.
For intersecting regions we do not have to choose between commutativity and associativity, we can have both.
In general, all that we can say the result is a hybrid relation but there are many cases where we can guarantee hybrid function status is preserved.


\begin{theorem}
	\label{thm:compatible1}
	Let $A$ and $B$ be hybrid sets over $U$ and let $f: U \to S$ be a function.
	Then $f^A \oplus f^B$ is a hybrid function.
	Moreover,
	\begin{equation}
		f^A \oplus f^B = f^{A \oplus B}
	\end{equation}
\end{theorem}


It should not be a surprise that the same function over different restrictions combine to form a function.
Let $(x,f(x)) \in f^A$ and $(y,f(y)) \in B$. Clearly, if $x=y$ then $f(x)=f(y)$. 
Since $f$ is common between both hybrid functions, there cannot be disagreement among points:
\begin{align*}
	f^A \oplus f^B 
		&= \bigoplus_{x \in U} A(x) \hset{ (x, f(x) )^1 } 
			\; \oplus \; \bigoplus_{x \in U} B(x) \hset{ (x, f(x) )^1 } \\
		&= \bigoplus_{x \in U} (A(x) + B(x)) \hset{ (x, f(x) )^1 } \\
		&= \bigoplus_{x \in U} (A \oplus B)(x) \hset{ (x, f(x) )^1 } \\ 
		&= f^{A \oplus B}
\end{align*}



Joining a function with itself is not the most interesting construction.
Generally piecewise function is desired for it's ability to tie together two \emph{different} functions.
If two functions have separate, non-overlapping regions, then our definition is again trivial.


\begin{theorem}
	\label{thm:compatible2}
	Given two function $f : U \to S$ and $g : U \to S$. The following identity holds if and only if $A$ and $B$ are disjoint:
	\begin{equation}
		f^A \oplus g^B = (f \fjoin g)^{A \oplus B}
	\end{equation}
\end{theorem}


Notice here the use of $\fjoin$ on the right hand side.
Here $\fjoin$ is the traditional (non-hybrid) function join as defined in (\ref{def:fjoin}).
$(f \fjoin g)$ was undefined for $\left( \supp(A) \cap \supp(B) \right)$ 
and so the equality will not hold if $A$ and $B$ are not disjoint.
Chaining several sums together we can represent the piecewise function $f$ from (\ref{eq_fP}) by:
\begin{equation*}
 	f^P = f^{P_1} \oplus f^{P_2} \oplus \ldots \oplus f^{P_n}
\end{equation*}



But disjointness is still too strong of a condition for two hybrid functions to be compatible.
The join of two non-disjoint functions may still be a hybrid function 
even if their respective functions do not agree at \emph{all} points.
So long as long as they agree on all points in overlapping regions intersection the functions can be safely joined.


\begin{definition}
	For hybrid functions $f^A$ and $g^B$, $f^A \oplus g^B$ is a hybrid function
	if and only if for all $x \in \supp (A \otimes B)$, we have $f(x) = g(x)$.
	We say that \textbf{$\boldsymbol{f^A}$ and $\boldsymbol{g^B}$ are compatible}.
\end{definition}


As with our definition of disjointness, we use the point-wise product $\otimes$ 
of hybrid sets as an analog for intersection $\cap$ of sets.
This definition also generalizes the two cases we have already seen in theorems 
\ref{thm:compatible1} and \ref{thm:compatible2}
The hybrid functions $f^A$ and $f^B$ are clearly compatible because $f$ agrees with itself everywhere.
For $A$ and $B$ disjoint, $f^A$ and $g^B$ are also compatible since $A \otimes B$ is empty;
there are no mutual points for $f$ and $g$ to disagree over.
Compatibility becomes less clear when we begin to consider multiple hybrid functions.
For one, compatibility is not associative.
Consider the following sequence:
\begin{equation*}
	(f^H \oplus g^H) \oplus g^{\ominus H} 
	= f^H \oplus (g^H \oplus g^{\ominus H}) 
	= f^H \oplus g^\emptyset = f^H
\end{equation*}
We know nothing of the compatibility of $f^H$ and $g^H$ but let us assume that they are not compatible.
However even though $(f^H \oplus g^H)$ is a hybrid relation it is compatible with $g^{\ominus H}$.
On the other hand, $g^H$ and $g^{\ominus H}$ are clearly compatible as an instance of theorem \ref{thm:compatible1}.
The result is a function over the empty set $g^{\emptyset}$ which is compatible with \emph{any} hybrid function.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% *-Reducible
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Hybrid Functional Fold}


Compatibility and reducibility are one way of collapsing a hybrid function to a traditional function.
Another approach is to fold or aggregate a hybrid function using some operator.
To aid in this we will first introduce some notation for iterated operators.
\begin{definition}
	Let $\op : S \times S \to S$ be an operator on $S$.
	Then, for $n > 0$, $n \in \mathbb{Z}$ we use $\op^n:S \times S \to S$ to denote iterated $\op$.
	So,
	\begin{equation}
		x \op^n y = (((x \overbrace{\op y) \op y) \op \ldots \op y)}^{n \text{ times}}
	\end{equation}
	If $\op$ has an identity $e_\op$, then we extend $x \op^0 y = x$.
	If $y$ has inverse $z$ under $\op$ then we use $x \op^{-1} y$ to denote $x \op^1 z$
	and extend this for any natural $n$ by $x \op^{-n} y$ by  $x \op^{n} z$.
	Finally, we allow $\op^n$ to be a unary operator, which we define by $\op^n x = e_\op \op^n x$.
\end{definition}

Assuming $\op^m$ and $\op^n$ are both defined (e.g. if $m,n \leq 0$ then $\op$ must be invertible),
we have $ ( x \op^m y ) \op^n y = x \op^{m+n} y$.
For non-associative groupoids, it may be of interest to instead define $\op^T$ for some tree $T$. 
For example $\op^n$ above is analogous to Haskell's \texttt{foldl}.
There are applications where \texttt{foldr}: $(x \op ( y \op ( y \op \ldots \op y)))$ or a balanced expression tree like \texttt{foldt} might be desired.
The applications we will be interested in will be over associative group operators and so we will not actually 
explore this any further.

\begin{definition}
	We say that a hybrid relation $f^A = f_1^{A_1} \oplus f_2^{A_2} \oplus \ldots$ over $T \times S$ 
	is $\op$\textbf{-reducible} if $(S, \op)$ is an abelian semi-group and $A$ is everywhere non-negative
	or if $(S, \op)$ is an abelian group, we allow for for negative $A$.
	If $f^A$ is $\op$-reducible we define its $\op$\textbf{-reduction}, $\mathcal{R}_\op(f^A) :  T \to S$ 
	as a (non-hybrid) function:
	\begin{equation}
		\mathcal{R}_\op (f^A)(x) = \restrict{\left(\op^{A_1(x)} f_1(x) \op^{A_2(x)} f_2(x) \op \ldots \right)}{\supp A}
	\end{equation}
\end{definition}


If $f^A$ is reducible then it is trivially $\op$-reducible and we have:
\begin{equation}
	\mathcal{R}(f^A) = \mathcal{R}_\op(f^A)
\end{equation}
If a hybrid function is already ``flattened'', then reducing it will do nothing.
So clearly $\mathcal{R}_\op$ is a projection since it is idempotent  (i.e. $\mathcal{R}_\op ( \mathcal{R}_\op( f^A)) = \mathcal{R}_\op(f^A)$).
Moreover, we can pull restrictions through point-wise sums:

\begin{equation}
	\mathcal{R}_\op( \mathcal{R}_\op(f^F) \oplus \mathcal{R}_\op(g^G)) =\mathcal{R}_\op( f^F \oplus g^G)
\end{equation}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Piecewise 1
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Example: \emph{Piecewise functions on generalized partitions}} 
\label{example:piecewise1}

Let $A_1 = [0,a)$, $A_2 = [0,1] \setminus A_1$, $B_1 = [0,b)$ and $B_2 = [0,1] \setminus B_1$ with  $a,b \in [0,1]$.
$\{ A_1, A_2\}$ and $\{B_1, B_2\}$ are two distinct partitions of the set $[0,1]$.
We will use these to define two piecewise functions $f$ and $g$ which map to some group $f,g:[0,1] \to G$.
\begin{equation*}
	f(x) = f_1^{A_1} \oplus f_2^{A_2}
		= \begin{cases}
			f_1(x) & x \in A_1 \\
			f_2(x) & x \in A_2
		\end{cases}
	\;\;\;\;\; \text{and} \;\;\;\;\;
	g(x) = g_1^{B_1} \oplus g_2^{B_2}
		= \begin{cases}
			g_1(x) & x \in B_1 \\
			g_2(x) & x \in B_2
		\end{cases}
\end{equation*}

If one were interested in computing their sum, $(f+g)$, the naive method would be to compute every possible intersection.
Over each intersection, one then takes the restriction of the corresponding sub-functions and joins all these terms together.
As in,
\begin{equation*}
	(f+g)(x) = \restrict{(f_1 + g_1)}{A_1 \cap B_1} 
		\fjoin \restrict{(f_1 + g_2)}{A_1 \cap B_2} 
		\fjoin \restrict{(f_2 + g_1)}{A_2 \cap B_1}
		\fjoin \restrict{(f_2 + g_2)}{A_2 \cap B_2}
\end{equation*}

We will take another approach.
First, we can partition $[0,1]$ into the generalized partition $A_1$, $B_1 \ominus A_1$, $B_2$.
The source of this particular partition will remain mysterious for now but observe that we can still construct the partitions:
$B_1 = (B_1 \ominus A_1) \oplus A_1$ and $A_2 = (B_1 \ominus A_1) \oplus B_2$.
And so we can represent $f$ and $g$ from above with a common partition by using:
\begin{align*}
	f &=  f_1^{A_1} \;\oplus\; f_2^{(B_1 \ominus A_1) \oplus B_2}
		\;=\; f_1^{A_1} \;\oplus\; f_2^{B_1 \ominus A_1} \;\oplus\; f_2^{B_2} \\
	g &= g_1^{A_1 \oplus (B_1 \;\ominus\; A_1)} \;\oplus\; g_2^{B_2}
		\;=\; g_1^{A_1} \;\oplus\; g_1^{B_1 \;\ominus\; A_1} \;\oplus\; g_2^{B_2}
\end{align*}


Since we have a common partition we can avoid computing pairwise intersections altogether and simply add each 
sub-function to the corresponding sub-function which shares a partition.
Since $\{ A_1 , B_1, (B_1 \ominus A_1) \}$ is a generalized partition, we will need to flatten the expression back down
to get a traditional function.
We use $\mathcal{R}_+$ for this so that negative regions properly cancel. 

\begin{equation*}
	(f+g)(x) = \mathcal{R}_+ \left( (f_1 + g_1)^{A_1} 
			\oplus (f_2 + g_1)^{B_1 \ominus A_1} 
			\oplus (f_2 + g_2)^{B_2} \right)
\end{equation*}


This equation holds regardless of the relative ordering of $a$ and $b$.
Suppose $x \in A_1 \cap B_1$
Then we have $A_1(x)= 1$ and $(B_1 \ominus A_1)(x) = B_2(x) = 0$.
And so $(f+g)(x) = (f_1 + g_1)(x)$.
Similarly, if $x \in B_1 \cap A_2$ or $x \in A_2 \cap B_2$ then 
only $(B_1 \ominus A_1)(x)$ or $B_2(x)$ will respectively be non-zero.
However, if $x \in B_2 \cap A_1$ then we have $A_1(x) = 1$, $(B_1 \ominus A_1)(x) = -1$ and $B_2(x) = 1$.
Simplifying this expression yields:
\begin{equation*}
	(f+g) \;=\; +^1 (f_1 + g_1) +^{-1} (f_2 + g_1) +^1 (f_2 + g_2) \;=\; (f_1 + g_2)
\end{equation*}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Refinement
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
In the above example only three regions could simultaneously exist.
If $a<b$ then $A_1 \cap B_2 = \emptyset$ but if $b<a$ then $A_2 \cap B_1 = \emptyset$.
Although it might seem that the three terms are a result of three regions, in the general case where 
$A_1$ and $B_1$ could be arbitrary subsets, we still only have three terms.
We will even extend this to any generalized partition.
First we will formalize some ideas we have already seen.


\begin{definition}
	A \textbf{refinement} of a generalized partition $P = \{P_i\}_{i \in I}$ is another generalized partition
	$Q = \{Q_j \}_{j \in J}$ such that, for every $P_i$ in $P$ there is a subset of $Q$: $\{ Q_{j} \}_{j \in J_i}$, 
	$J_i \subseteq J$ such that for some integers $\{a_{ij}\}_{j \in J_i}$
	\begin{equation}
		P_i = \bigoplus_{j \in J_i} a_{ij} Q_{j}
	\end{equation}
	Given a \emph{set} of generalized partitions a \textbf{common refinement} is a generalized partition which is a 
	refinement of every partition in the set. 
	A refinement $Q$ of $P$ is \textbf{strict} if $\supp(Q) = \supp(P)$.
\end{definition}


In our previous example we used $\{ A_1, B_1 \ominus A_1, B_2 \}$ which was a common refinement of both
$\{ A_1, A_2 \}$ and $\{ B_1, B_2 \}$.
$A_1$ and $B_2$ have trivial representations while $A_2 = (B_1 \ominus A_1) \oplus B_2$ and 
$B_1 = A_1 \oplus (B_1 \ominus A_1)$.
Another common refinement would be the trivial $\{ A_1, B_1, A_2, B_2 \}$
This is less preferable due to not only containing 4 regions instead of 3 but also the point-wise sum is $[0,1]^2$
instead of the reducible $[0,1]$.


We can now formally phrase the problem.
Let $A=\{ A_i \}_{i=1}^n$ and $B=\{ B_i \}_{i =1}^m$ be two generalized partitions of a hybrid set $U$.
We wish to find a generalized partition $C$  of $U$ which is a \emph{common}, \emph{strict} refinement of $A$ and $B$
and has minimal cardinality.
These conditions can be summarized into the following system of $n+m+1$ simultaneous equations:
\begin{equation*}
	U = \bigoplus_j C_j
\end{equation*}
\begin{equation*}
	\forall i \in 1 \ldots n : \;\;\;\;\; A_i = \bigoplus_{j}  a_{i,j} C_j
\end{equation*}
\begin{equation*}
	\forall i \in 1 \ldots m : \;\;\;\;\; B_i = \bigoplus_{j} b_{i,j} C_j
\end{equation*}
for some integers $a_{i,j}$ and $b_{i,j}$.
Since we know that $A$ and $B$ are each separately partitions of $U$, 
we can leverage some of their dependencies to construct $\{C_j\}$.
For example, $A_n$ can be represented as $U \ominus ( A_1 \oplus \ldots \oplus A_{n-1} )$.
Any $A_i$ or $B_i$ could similarly be represented by the point-wise difference with $U$.
Although we could remove any two pieces from $A$ and $B$, we will choose to remove $A_n$ and $B_n$ to form a set of
$n+m-1$ pieces to form a linearly independent basis for $C$.
Expressed as a linear system we have:


\begin{equation*}
	M \cdot 
		\begin{pmatrix}
			C_1 	\\
			\vdots 	\\
			C_{n+m-1}
		\end{pmatrix}
	=
		\begin{pmatrix}
			U 		\\[-0.5em] 
			A_1 	\\[-0.5em] 
			\vdots 	\\[-0.5em] 
			A_{n-1}	\\[-0.5em] 
			B_1 	\\[-0.5em] 
			\vdots 	\\[-0.5em] 
			B_{m-1}
		\end{pmatrix}
	\;\;\;\;\;\;\text{ where }\;\;
	M = \begin{pmatrix}
			1			& 1			& \cdots 	& 1 					\\[-0.5em]
			a_{1,1}		& a_{1,2}	& \cdots 	& a_{1, n+m-1} 		\\[-0.5em]
			\vdots 		&			&			& \vdots 			\\[-0.5em]
			a_{n-1,1}	& a_{n-1, 2}	& \cdots 	& a_{n-1, n+m-1} 	\\[-0.5em]
			b_{1,1} 		& b_{1,2} 	& \cdots 	& b_{1, n+m-1}		\\[-0.5em]
			\vdots 		& 			&			& \vdots 			\\[-0.5em]
			b_{m-1,1} 	& b_{m-1,2}	& \cdots 	& b_{m-1,n+m-1}
	\end{pmatrix}
\end{equation*}


By definition, $M$ is an integer matrix.
But we are actually more interested in its inverse $M^{-1}$ as this will give us values for $C_i$ 
relative to $( U, A_1, \ldots, A_{m-1}, B_1, \ldots, B_{m-1} )$.
To stay in the realm of hybrid sets, we would also like to enforce that $M^{-1}$ is also an integer matrix.
Assuming this, then the determinant of $M$ must be $\pm 1$.
Further restricting ourselves to upper triangular matrices we can choose $M$ to be all 1's along the diagonal
as well as the top row. 
Which has the following inverse:
\begin{equation*}
	\begin{pmatrix}
		1 		&\cdots 	&\cdots 	&\cdots 	& 1 		\\[-0.5em]
		0		& 1		& 0 		&\cdots 	& 0 		\\[-0.5em]
		\vdots 	&\ddots 	&\ddots 	&\ddots 	&\vdots 	\\[-0.5em]
		\vdots 	&		&\ddots 	&\ddots 	& 0 		\\[-0.5em]
		0 		&\cdots 	&\cdots 	& 0 		& 1
	\end{pmatrix}^{-1}
	= \; \; \;
	\begin{pmatrix}
		1 		&-1	 	&\cdots 	&\cdots 	& -1		\\[-0.5em]
		0		& 1		& 0 		&\cdots 	& 0 		\\[-0.5em]
		\vdots 	&\ddots 	&\ddots 	&\ddots 	&\vdots 	\\[-0.5em]
		\vdots 	&		&\ddots 	&\ddots 	& 0 		\\[-0.5em]
		0 		&\cdots 	&\cdots 	& 0 		& 1
	\end{pmatrix}
\end{equation*}
Using this, we find that one choice for $C$ the common refinement for $A$ and $B$, is:
\begin{equation*}
	C = \Big\{\; 
	(U \ominus A_1 \ominus \ldots \ominus A_{n-1} \ominus B_1 \ominus \ldots \ominus B_{n-1}), \;\;
	A_1, A_2, \ldots, A_{n-1}, \;\; B_1, B_2, \ldots, B_{m-1}
	\;\Big\}
\end{equation*}


Finally, to generalize the example from \ref{example:piecewise1}, let $f = f_1^{A_1} \oplus f_2^{A_2} \oplus f_n^{A_n}$
and  $g = g_1^{B_1} \oplus \ldots \oplus g_m^{B_m}$ be two piecewise functions over a common domain $U$.
We can express both of these functions in terms of the above common refinement by:
\begin{align*}
	f &= f_1^{A_1} \oplus \ldots \oplus f_{n-1}^{A_{n-1}} \oplus f_n^{U \oplus B_1 \oplus \ldots \oplus B_{m-1}} \\
	g &= g_1^{B_1} \oplus\ldots \oplus g_{m-1}^{B_{m-1}} \oplus g_m^{U \oplus A_1 \oplus\ldots \oplus A_{n-1}}
\end{align*}
To compute $(f \op g)$ one just needs to collect like terms and encapsulate in a $\op$-reduction
\begin{align}
	\label{eqn:piecewiseOp}
	f \op g = \; \mathcal{R}_\op  \; & \!\!\! \left( \,
			(f_1 \op g_m)^{A_1} 
			\oplus \ldots \oplus 
			 (f_{n-1} \op g_m)^{A_{n-1}} \right. \notag \\
		\oplus & \;
			 (f_n \op g_1)^{B_1} 
			\oplus \ldots \oplus 
			 (f_n \op g_{m-1})^{B_{m-1}} \\
		\oplus & \left. 
			 (f_n \op g_m)^{U \ominus (A_1 \oplus \ldots \oplus A_{n-1} \oplus B_1 \oplus \ldots \oplus B_{m-1})}
		\; \right) \notag
\end{align}

  
  



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% PSEUDO-FUNCTIONS
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Pseudo-functions}


One last detail remains to be settled.
So far we have assumed that the sub-functions of $f$ and $g$ are defined over \emph{all} of $U$.
This may not be the case, we would like to only require $f_i$ to at least be defined over its corresponding part $A_i$
and similarly $g_j$ over $B_j$.
This poses a problem for the previous equation (\ref{eqn:piecewiseOp}) when evaluated at say $x \in A_1 \cap B_1$.
Then we have the following terms with non-zero multiplicity:
\begin{equation*}
	(f \op g)(x) = 
		\mathcal{R}_\op \left(   
			(f_1(x) \op g_m(x))^1 \oplus 
			(f_n(x) \op g_1(x))^1 \oplus 
			(f_n(x) \op g_m(x))^{-1} 
		\right)
\end{equation*}


We would like for the $g_m(x)$ in the first term to cancel with the $g_m(x)$ in the third term.
Similarly $f_n(x)$ in the second term should cancel with the $f_n(x)$ in the third term leaving only $f_1(x) * g_1(x)$.
This requires that $g_m(x)$ and $f_n(x)$ to actually be defined which is more than we'd care to assume.
The approach we take instead is to delay the evaluation of functions until cancellations occur.
To do this we use a lambda-lifting trick.
Instead of having the elements of a hybrid function be pairs containing the input and output of the underlying function 
we consider them as pairs containing the input and a ``function pointer'' to the underlying function.


\begin{definition}
	We define a pseudo-function $\pseudo{f\;}^A$ as:
	\begin{equation}
		\label{eqn:pseudofunc}
 		\pseudo{f\;}^A = \bigoplus_{x \in B} A(x) \hset{(x,f)^1}
	\end{equation}
\end{definition}


One should notice the similarity between (\ref{eqn:pseudofunc}) and (\ref{eqn:hfunc}).
The difference is that we have replaced $(x, f(x))$ with the unevaluated $(x,f)$.
This formally makes $\pseudo{f\;}^A$ a hybrid relation over $U \times (U \to S)$ as opposed to 
a hybrid function over $U \times S$.
To evaluate $\pseudo{f\;}^A$ we map back to $f^A$ and evaluate that.
This mapping between $(x,f(x))$ and $(x,f)$ is very natural and we will perform it unceremoniously,
often using $f^A$ and $\pseudo{f\;}^A$ interchangeably. 
Properties of hybrid functions such as compatibility and reducibility will be lifted to hybrid pseudo-functions by this as well.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Piecewise 2
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Example: \emph{Piecewise functions revisited}}


We repeat the example from \ref{example:piecewise1} but concretely use the following function:
\begin{equation*}
	f(x) = \begin{cases}
		(2-x^2) & -1 \leq x \leq 1\\
		1/x^2 & \text{otherwise}
	\end{cases}
\end{equation*}
Graphically, this resembles a bell-shaped curve with no discontinuities or any apparent irregular behavior. 
This can be seen in the black plot below in Figure~\ref{fig:pwRational}.
Although $f$ is defined for all of $\mathbb{R}$, this is not the case for its sub-functions. 
The plots in red and blue show the behavior of $(2-x^2)$ and $1/x^2$ respectively outside of their defined ranges in $f$.
Of note, $1/x^2$ (shown in blue) is obviously undefined at 0.


\begin{figure}[ht]  
	\centering 
	\begin{tikzpicture}[>=stealth]
	    \begin{axis}[
	        xmin=-5,xmax=5,
	        ymin=-2,ymax=10,
	        axis x line=middle,
	        axis y line=middle,
	        axis line style=<->,
	        xlabel={$x$},
	        ylabel={$y$},
	        ]
	        \addplot[no marks,blue,->] expression[domain=-1:-0.33,samples=100]{1/x^2};
	        \addplot[no marks,blue,<-] expression[domain=0.33:1,samples=100]{1/x^2};
	        
	        \addplot[no marks,red,<-] expression[domain=-2:-1,samples=100]{2 - x^2};
	        \addplot[no marks,red,->] expression[domain=1:2,samples=100]{2 - x^2};
		
		\addplot[no marks,black,thick,-] expression[domain=-1:1,samples=100]{2 - x^2};
	      \addplot[no marks,black,thick,<-] expression[domain=-4:-1,samples=100]{1/x^2};
	      \addplot[no marks,black,thick,->] expression[domain=1:4,samples=100]{1/x^2};
	    \end{axis}
	\end{tikzpicture}
	\caption[Piecewise Rational Function] {
		A piecewise rational function is shown in black. 
		The plots in red and blue are continuations of $(2-x^2)$ and $1/x^2$ respectively.
	\label{fig:pwRational}}
\end{figure}


To represent $f$ as a hybrid function, we partition the real line into the sets $A_1 = [-1,1]$ and 
$A_2 = \mathbb{R} \setminus [-1,1] = (-\infty, -1) \oplus (1, \infty)$.
This gives the closely related hybrid function $f$ and pseudo-function $\pseudo{f\;}$:


\begin{equation*}
	\begin{array}{r c c c}
	f 			=& \left(2-x^2\right)^{A_1}			&\oplus&	\left(1/x^2\right)^{A_2} \\
	\pseudo{f\;} =& \left(x \mapsto 2-x^2\right)^{A_1}	&\oplus&	\left(x \mapsto 1/x^2\right)^{A_2}
	\end{array}
\end{equation*}



Additionally we will multiply $f$ by the Heaviside function $H$: a piecewise function over the intervals
$B_1 = [0, \infty)$ and $B_2 = (-\infty, 0)$ defined as follows:
\begin{equation*}
	\begin{array}{r c c c}
		H			=& (1)^{B_1} 			&\oplus& 	(0)^{B_2} \\
		\,\pseudo{\!H} 	=& (x \mapsto 1)^{B_1}	&\oplus& 	(x \mapsto 0)^{B_2}
	\end{array}
\end{equation*}
In both the pseudo and non-pseudo function cases, we first need to find a minimal common refinement.
As before, we can construct the common refinement ${P = \{ P_1, P_2, P_3 \}}$:
\begin{align*}
	P_1 &\;=\; A_1 \;=\; [-1,1] \\
	P_2 &\;=\; B_1 \;=\;  [0, \infty) \\
	P_3 &\;=\; U \ominus (A_1 \oplus B_1) \;=\;  \mathbb{R} \ominus [-1,1] \ominus [0, \infty)
\end{align*}
To illustrate the problem with using (non-pseudo) hybrid functions, we shall consider $f\cdot H$ evaluated at 0. 
Since $f(0)=2$ and $H(0)=1$ we expect $(f\cdot H)(0)=2$.
Following from (\ref{eqn:piecewiseOp}), we construct a hybrid function and \emph{attempt}:
\begin{align*}
	(f \cdot H)(0) 
		&= \mathcal{R}_\times \left( 
			\left( (2-x^2)(0) \right)^{P_1} \oplus 
			\left( (1/x^2)(1) \right)^{P_2} \oplus 
			\left( (1/x^2)(0) \right)^{P_3} \right)(0) \\
		&= \mathcal{R}_\times \left( 
			\left( (2-0^2)(0) \right)^{1} \oplus 
			\left( (1/0^2)(1) \right)^{1} \oplus 
			\left( (1/0^2)(0) \right)^{-1} \right)\\
		& = \frac{(2-0^2)(0) \cdot (1)(1) \cdot (0^2)(1)}{(1)(1) \cdot (0^2)(1) \cdot (1)(0)}
\end{align*}
But it is not so easy to argue that this evaluates to 2.
Alternatively, we could use the very similar pseudo-function:
\begin{align*}
	\pseudo{f\;} \cdot \,\pseudo{\!H} = \mathcal{R}_\times \bigg(
				& \left( (x \mapsto 2-x^2) \cdot (x \mapsto 0) \right)^{P_1} \notag \\
		\oplus \;& \left( (x \mapsto 1/x^2) \cdot (x \mapsto 1) \right)^{P_2} \notag \\
		\oplus \;& \left( (x \mapsto 1/x^2) \cdot (x \mapsto 0) \right)^{P_3} 
	\bigg)
\end{align*}


Leaving these functions unevaluated is the key to making non-total functions work.
Once again, we evaluate each of $P_1$, $P_2$ and $P_3$ at 0 and find:
\begin{align*}
	(\pseudo{f\;} \cdot \,\pseudo{\!H})(0) = \mathcal{R}_\times \bigg(
				& \left( (x \mapsto 2-x^2) \cdot (x \mapsto 0) \right)^1 \notag \\
		\oplus \;& \left( (x \mapsto 1/x^2) \cdot (x \mapsto 1) \right)^1 \notag \\
		\oplus \;& \left( (x \mapsto 1/x^2) \cdot (x \mapsto 0) \right)^{-1} 
	\bigg)(0)
\end{align*}
Once we have this, we can then evaluate the $\times$-reduction on the still unevaluated functions.
Clearly $x \mapsto 0$ occurs with canceling signs as does $x \mapsto 1/x^2$.
This leaves us with the product of two unevaluated functions:
\begin{equation*}
	(\pseudo{f\;}\cdot\,\pseudo{\!H})(0) = \left((x \mapsto 2-x^2) \cdot (x \mapsto 1)\right)
\end{equation*}
\emph{After} these cancellations occur, then we can evaluate $(f \cdot H)(x)$ by way of
$((\pseudo{f\;}\cdot\,\pseudo{\!H})(x))(x)$:
\begin{align*}
	(f \cdot H)(0) 
		\;\;=\;\; \left(\left(\pseudo{f\;} \cdot \,\pseudo{\!H}\right)(0)\right)(0) 
		\;\;=\;\; \left((x \mapsto 2-x^2) \cdot (x \mapsto 1)\right)(0)
		\;\;=\;\; 2
\end{align*}


Aside from the introduction of $\R[\op]$ as a correction to the $\obar^\op$ operation, 
the material of this chapter can be found entirely in \cite{carette2010}.
Given this foundation, the following four chapters will explore new applications for hybrid sets and functions.
Matrix addition with block matrices was also explored in \cite{carette2010} as well as \cite{sexton2008abstract}.
In the following chapter these will be revisited and extended. 
A novel technique for matrix multiplication will also be presented.
The next obvious application for hybrid sets is as oriented domain of integration.
We will perform an otherwise standard treatment of integration but for the new usage of hybrid sets and oriented intervals.
There are other ways to deal with orientation in Lebesgue integrals but hybrid sets will allow us do so directly without 
the need to ``sanitize'' domains.
Finally all of our work with integrals and piecewise functions will culminate in chapter 6 with a novel approach to 
convolution of piecewise functions over symbolic intervals.






