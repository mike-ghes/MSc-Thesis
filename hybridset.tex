\chapter{Hybrid Set Theory}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% PIECEWISE
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


The motivation behind hybrid sets and functions can be traced to wanting a better approach to piecewise functions.
Piecewise functions are enormously useful constructions in many areas (...)
The perennial example of a piecewise function is $\mathrm{abs}:\mathbb{R} \to \mathbb{R}_{+} \cup \{ 0 \}$ given in the form:
\begin{equation}
	\mathrm{abs}(x) = 
  		\left\{
     			\begin{array}{lr}
       			-x & : x < 0 \\
       			x & : x \geq 0
     			\end{array}
   		\right.
\end{equation}


To evaluate abs for an argument $x$, one must first determine which sub-function to use. 
If $x < 0$ then the first case is evaluated and abs will return the result of $x \mapsto -x$. 
Otherwise, if $x \geq 0$ the second case is evaluated and the result of $x \mapsto x$ is returned. 
Rather than as a condition, we could just as easily think of ``$x<0$'' and ``$x \geq 0$'' as partitions of the real line.
Evaluation then occurs by checking whether $x\in \mathbb{R}_{+} \cup \{ 0 \} $ or $x \in \mathbb{R}_{-}$.
In general, a piecewise function $f$ will take the form:
\begin{equation}
\label{eq_fP}
	f(x) = 
	  \left\{
	     \begin{array}{lr}
	       f_1(x) & : x \in P_1 \\
	       f_2(x) & : x \in P_2 \\ 
	       \vdots & \vdots \\
	       f_n(x) & : x \in P_n
	     \end{array}
	   \right.
\end{equation}
where the set $\{ P _ i \}$ forms a partition of the domain of $f$ and for each $f_i$ is defined over all of the corresponding $P_i$. To formalize this we require the ability to restrict a function's domain and join disjoint pieces together.


\begin{definition}
	Given a function $f:X \to Y$ for any subset of the domain, 
	$Z \subset X$, the \emph{restriction of $f$ to $Z$} is the function $f|_Z : Z \to Y$, 
	such that $f|_Z(x) = f(x)$ for all $x \in Z$.
\end{definition}


\begin{definition}
	Define $\fjoin$, the \emph{join} of two functions, $f$ and $g$ by:
	\begin{equation}
	\label{def:fjoin}
		f \fjoin g =  
		\left\{
	     		\begin{array}{lr}
	       		f(x) & \text{if } g(x) = \bot \\
	       		g(x) & \text{if } f(x) = \bot \\
	       		\bot & otherwise
	     		\end{array}
	   	\right.
	\end{equation}
\end{definition}
\todo[inline]{Is there a way to define without using piecewise functions?}


This allows us to re-write our previous definition of (\ref{eq_fP}) as:
\begin{equation}
	\label{fjoin_partition}
	f = \restrict{f}{P_1} \fjoin \restrict{f}{P_2} \fjoin \ldots \fjoin \restrict{f}{P_n}
\end{equation}
\todo[inline]{To Do: problem with this approach + join}


But we must be careful as this definition is not associative.
Let $x \in A \cap B \cap C$, 
then $( (\restrict{f}{A} \fjoin \restrict{g}{B} ) \fjoin \restrict{h}{C} )(x) = h(x)$ 
but $( \restrict{f}{A} \fjoin ( \restrict{g}{B} \fjoin \restrict{h}{C} ))(x) = f(x)$


Other conventions exist, for example \emph{Maple}'s 
\texttt{piecewise(cond\_1, f\_1, cond\_2, f\_2, \ldots, cond\_n, f\_n, f\_otherwise)} 
effectively uses a short-circuted $\fjoin$;
it takes the first sub-function, \texttt{f\_i}, such that the corresponding condition, \texttt{cond\_i}, evaluates to \emph{true}.
This approach simply trades associativity for commutivity.
In this section we will construct a formal system to manipulate partial functions more elegantly.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% HYBRID SET
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Hybrid Sets}


\todo[inline]{To Do: join}
We shall consider \emph{hybrid sets}: 
an extension of multisets which has multiplicities ranging over $\mathbb{N}_0$, 
a hybrid set has multiplicities over all of $\mathbb{Z}$.

However first we must establish \emph{partial sets} (unrelated to a \emph{poset} or ``partially ordered set'').

Similar to a partial function being only partially defined over its domain, 
for a partial set, there may exist some items for which membership is undefined.


For an underlying set $U$ we will consider a hybrid set as a function $U \to \mathbb{Z}$ as a way to track the multiplicities of any particular element.

\begin{definition}
	Let $U$ be a universe, then any function $U \to \mathbb{Z}$ is called a \emph{hybrid set}.
\end{definition}

On its own, this definition does us very little good; much of the usefulness of sets is derived from their rich notation.

\begin{definition}
	Let $H$ be a hybrid set. 
	Then we say that $H(x)$ is the \textbf{multiplicity} of the element $x$. 
	We write, $x \in^n H$ if $H(x)=n$. 
	Furthermore we will use $x \in H$ to denote $H(x)\neq 0$ (or equivalently, $x \in^n H$ for $n\neq 0$).
	Conversely, $x \notin H$ denotes $x \in^0 H$ or $H(x)=0$.
	The symbol $\emptyset$ will be used to denote the empty hybrid set for which all elements have multiplicity 0.
	Finally the \textbf{support of a hybrid set} is the (non-hybrid) set $\text{supp }H$,
	where $x \in \text{supp }H$ if and only if $x \in H$
\end{definition}


We will use the notation:
\begin{equation*}
	H = \hset{x_1^{m_1}, x_2^{m_2},\ldots}
\end{equation*}
to describe the hybrid set $H$ where the element $x_i$ has multiplicity $m_i$. 
We allow for repetitions in $\{ x_i \}$ but interpret the overall multiplicity of an element $x_i$ as 
the sum of multiplicities among copies. This is, (using Iverson brackets):
\begin{equation}
	H(x) = \sum_{x_i \in^{m_i} H} [x = x_i] \; m_i
\end{equation}
For example, $H=\hset{a^1, a^1, b^{-2}, a^3, b^1} = \hset{a^5, b^{-1}}$. 
A writing in which $x_i \neq x_j$ for all $i \neq j$ is refered to as a \emph{normalized form} of a hybrid set. 
For normalized hybrid sets it follows that $H(x_i) = m_i$.



Traditional sets use the operations $\cup$ union, $\cap$ intersection, and $\setminus$ complementation.
In the same way a hybrid set is a function $H : U \to \mathbb{Z}$, 
a set could be considered as function $S : U \to \{ 0,1 \}$.
Then set operations correspond to point-wise \texttt{OR}, \texttt{AND}, and \texttt{NOT}.
That is, for two sets $A$ and $B$, then $(A \cup B)(x) = A(x) \;\mathtt{OR}\; B(x)$.
One could easily extend union and intersection to hybrid sets using point-wise min and max
%%%%%%%%%%%%%%%%%%%%%%%%%%
[cite],
but it would make more sense to have operations corresponding to primitive operations in $\mathbb{Z}$ instead.
Thus we will define $\oplus$, $\ominus$, and $\otimes$ by point-wise $+$, $-$, and $\cdot$.

\begin{definition}
	For any two hybrid sets $A$ and $B$ over a common universe $U$, 
	we define the operations $\oplus, \ominus, \otimes : \mathbb{Z}^U \times \mathbb{Z}^U \to \mathbb{Z}^U$ 
	such that for all $x \in U$:
	\begin{equation}
		(A \oplus B)(x) = A(x) + B(x)
	\end{equation}
	\begin{equation}
		(A \ominus B)(x) = A(x) - B(x)
	\end{equation}
	\begin{equation}
		(A \oplus B)(x) = A(x) \cdot B(x)
	\end{equation}
	We also define, $\ominus A$ as $\emptyset \ominus A$ and for $c \in \mathbb{Z}$:
	\begin{equation}
		(cA)(x) = c \cdot A(x)
	\end{equation}
\end{definition}


\begin{definition}
	We say \textbf{$\boldsymbol{A}$ and $\boldsymbol{B}$ are disjoint} if and only if $A \otimes B = \emptyset$
\end{definition}

Taken alone, hybrid sets can be used to model various objects. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Rational Numbers
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Example: \emph{Rational Arithmetic}}


Any positive rational number can be represented as a hybrid set over the set of primes and vice versa  
(i.e. ($\mathbb{Z}^\mathbb{P}, \oplus) \simeq (\mathbb{Q}_+,\cdot)$).
For any rational number $a/b$, both $a$ and $b$ being integers will have a prime decomposition: 
$a=p_1^{m_1}\cdot p_2^{m_2} \cdot \ldots$ and $b=q_1^{n_1} \cdot q_2^{n_2} \cdot ...$ . 
Then there is an isomorphism:
\begin{equation}
	f(a/b) = \hset{p_1^{m_1}, p_2^{m_2}, \ldots} \ominus \hset{q_1^{n_1}, q_2^{n_2}, \ldots}
\end{equation}

\begin{example}
	Concretely, we have:
	\begin{equation*}
		20/9 \cdot 15/8 
			= \hset{5^1, 2^2, 3^{-2}} \oplus \hset{5^1, 3^1, 2^{-3}} 
			= \hset{5^2, 2^{-1}, 3^{-1}} 
			= 25/6
	\end{equation*}
\end{example}

%%%%%%% word choice: ``consolidate''
Typically one would need to specify equivalence classes on $\mathbb{Q}$ to consolidate the identity $ca/cb = a/b$.
With hybrid set representation, this identity comes for free:
any common factor between numerator and denominator will cancel result in cancelling multiplicities. 
For example, $2/4 = \hset{2^1, 2^{-2}}$ which is the un-normalized form of $\hset{2^{-1}} = 1/2$.


\todo[inline]{Is there a (nice!) way to extend this for 0 and negative $\mathbb{Q}$ that preserves uniqueness up to normalization? }%%%%%%%%%%%%%%%%%%%


%Monic polynomial

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Rational Polynomials
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Example: \emph{Rational Polynomials}}

Hybrid sets can also be used to represent the roots and asymptotes of a rational polynomial.
\todo[inline]{Blending}
\begin{example} Concretely: 
	\begin{equation}
		\frac{(x-2)}{(x-1)^2(x+1)} = \hset{ 2^1, 1^{-2}, -1^{-1} }
	\end{equation}
\end{example}

\newpage

In traditional set theory, a partition of $X$ is a collection of subsets of $X$ such that 
the subsets are mutually disjoint and their union is equivalent to $X$.
When dealing with hybrid sets we no longer have union but use point-wise sum instead.


\begin{definition}
	A \textbf{generalized partition $\boldsymbol{P}$ of a hybrid set $\boldsymbol{H(x)}$} is a sequence of hybrid sets
	$P=\{P_i \}_{i=1}^n$ such that
	\begin{equation}
		P_1 \oplus P_2 \oplus \ldots \oplus P_n = H
	\end{equation}
	We say that \textbf{$\boldsymbol{P}$ is a strict partition of $\boldsymbol{H}$} if 
	$P_i$ and $P_j$ are disjoint for all $i \neq j$.
\end{definition}


Traditional boolean sets can be trivially converted to hybrid sets.
For a set $X$, this is done simply by taking $H(x)=1$ if $x \in X$ and $H(x)=0$ if $x \notin X$.
In this way any traditional set partition is a strict, generalized set partition.
By principle of inclusion-exclusion, 
\begin{equation*}
	P_i \cup P_j = P_i \oplus P_j \ominus (P_i \cap P_j)
\end{equation*}
Since $P_i$ and $P_j$ are disjoint then we have that $\bigcup_i P_i = \bigoplus_i P_i$ and thus a strict partition.
What about the converse, how do generalized partitions relate to partitions?
First we must consider that not all hybrid sets can be cast back down to traditional sets.


\begin{definition}
	Given a hybrid set $H$ over universe $U$, 
	if for all $x \in U$ $H(x)=1$ or $H(x)=0$ then we say that \textbf{$\boldsymbol{H(x)}$ is reducible}.
	If $H$ is reducible then we denote the \textbf{reduction of $\boldsymbol{H}$} by $\mathcal{R}(H)$ 
	as the (non-hybrid) set over $U$ with the same membership.  
\end{definition}


If a hybrid set $H$ is reducible, we still cannot be guaranteed that a generalized partition $P$ of $H$ will be a strict.
Consider the reducible hybrid set $[0,1]$ (that is, $H(x)=1$ if $0 \leq x \leq 1$ and $H(x)=0$ otherwise).
Then $P = \big\{ [0,2], \ominus (1,2] \big\}$ is a generalized partition of $H$. 
A generalized partition of a reducible set is strict if and only if each generalized partition is reducible.
Generalized partitions and reducibility will be very useful to us over the next section.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% HYBRID FUNCTIONS
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Hybrid Relations}


A function is typically defined as a mapping from elements of one set to another set.
We will consider functions which have hybrid sets as their domain (but still map to traditional sets) 
which we will call \emph{hybrid functions}.
But first we must establish \emph{hybrid relations}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Hybrid Relation
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{definition}
	For two sets $S$ and $T$, a hybrid set over their Cartesian product $S \times T$ is called a 
	\textbf{hybrid (binary) relation between $\boldsymbol{S}$ and $\boldsymbol{T}$}.
	We denote the set of all such hybrid relations by $\mathbb{Z}^{S \times T}$. 
\end{definition}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Ordering Algebra
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Example: \emph{Algebra of Orderings}}
Consider a set $S$ with some ordering $\succ$.
Then we can define the hybrid relations $[\succ]$ and $[=]$ as a hybrid relations between $S$ and itself 
(i.e. elements of $\mathbb{Z}^{S\times S}$).
Which we define as,
\begin{equation}
	[\succ] = \hset{ (x,y)^1, (y,x)^{-1} : x \succ y }
\end{equation}
\begin{equation}
	[=] = \hset{ (x,x)^1, : x \in S }
\end{equation}
These hybrid relations can then be algebraically manipulated to create other relations on $S$.
For example, we can construct their respective dual relations $[\prec]$ and $[\neq]$ as well as the non-strict $[\succeq]$:
\begin{equation}
	[\prec] = \ominus [\succ]
\end{equation}
\begin{equation}
	[\neq] = (S\times S) \ominus [=]
\end{equation}
\begin{equation}
	[\succeq] = [=] \oplus [\succ]
\end{equation}
We can even use supp to define the notion of a total ordering.
We say that $\succeq$ is a total ordering of $S$ if:
\begin{equation}
	\text{supp}[\succeq] = S \times S
\end{equation}


\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Hybrid Function
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Hybrid Functions}
\begin{definition}
	A \textbf{hybrid function from $\boldsymbol{S}$ to $\boldsymbol{T}$} is 
	a hybrid relation $H$ between $S$ and $T$ such that $(x,y) \in H$ and $(x,z) \in H$ implies $y=z$.
	We denote the set of all such hybrid functions by $\mathbb{Z}^{S \to T}$.
\end{definition}


Although this tells us what \emph{is} and \emph{is not} a hybrid function, it is not the most useful definition to work with. 
We would like to think of a hybrid function not as a mapping from a hybrid set to a boolean set but as
a function between two sets with a multiplicity attached to each mapping.
From this perspective, we would generally have a function and hybrid set already in mind.
Given a hybrid set $H$ over $U$ and a function $f:B \to S$ be a function where $B \subseteq U$ and $S$ a set.
Then we denote by $f^H$ the hybrid function from $B$ to $S$ defined by:
\begin{equation}
	\label{hfunc}
	f^H := \bigoplus_{x \in B} H(x) \hset{ (x, f(x) )^1 }
\end{equation}


There is little literature or established use for hybrid functions;
their primary use to us will be as something that we can turn back into traditional functions.
One may notice that we have defined hybrid functions by their graph,
taking the reduction (if it exists) of a hybrid function one naturally gets the graph of a function.


\begin{definition}
	If $H$ is a reducible hybrid set, then \textbf{$\boldsymbol{f^H}$ is a reducible hybrid function}. 
	Additionally, if $f^H$ is reducible, we extend $\mathcal{R}$ by:
	\begin{equation}
		\mathcal{R}(f^H)(x) = \restrict{f}{\mathcal{R}(H)}(x)
	\end{equation}
\end{definition}


Since $\mathcal{R}(H)$ only exists if $H(x)$ is everywhere 0 or 1; 
$\mathcal{R}(f^H)$ only makes sense when $f^H$ is reducible.
Assuming that we end up with a reducible function, hybrid functions make an excellent primitives to construct piecewise functions.
Earlier in (\ref{def:fjoin}) we defined the \emph{join of functions} to allow us to construct piecewise functions from \emph{restricted functions}.
The join of two hybrid functions is quite trivially defined.

 
\begin{definition}
	The \textbf{join}, $f^F \hjoin g^G$ of two hybrid functions $f^F$ and $g^G$ is 
	the hybrid relation given by their point-wise sum.
	\begin{equation} \label{def:hjoin}
		f^F \hjoin g^G := f^F \oplus g^G
	\end{equation}
\end{definition}


However, we will immediately dispense with using $\hjoin$ altogether and simply use $\oplus$ 
in order to prevent confusion between hybrid functional join and traditional functional join when they occur together.
It is important to note that the join operator is closed under hybrid relations but not under hybrid functions.
For any two hybrid \emph{functions} the result will be a hybrid \emph{relation} 
but not necessarily another hybrid function.
We must still be wary of overlapping regions but there are some cases where we can be guaranteed to get a hybrid function.
This definition is still nearly as ``dangerous'' as non-hybrid functional join 
but crucially, overlapping regions are not forgotten.


\begin{theorem}
Let $A$ and $B$ be hybrid sets over $U$ and let $f: U \to S$ be a function.
Then $f^A \oplus f^B$ is a hybrid function.
Moreover,
	\begin{equation}
		f^A \oplus f^B = f^{A \oplus B}
	\end{equation}
\end{theorem}



Clearly, if $(x,f(x)) \in f^A$, $(y,f(y)) \in B$ and $x=y$ then $f(x)=f(y)$.
Since $f$ is common between both hybrid functions, there cannot be disagreement among points.
Additionally,
\begin{align}
	f^A \oplus f^B 
		&= \bigoplus_{x \in U} A(x) \hset{ (x, f(x) )^1 } 
			\; \oplus \; \bigoplus_{x \in U} B(x) \hset{ (x, f(x) )^1 } \notag \\
		&= \bigoplus_{x \in U} (A(x) + B(x)) \hset{ (x, f(x) )^1 } \notag \\
		&= \bigoplus_{x \in U} (A \oplus B)(x) \hset{ (x, f(x) )^1 }
\end{align}


Inductively, this holds for any number of hybrid sets with a common function.
For instance, given any generalized partition $P = P_1 \oplus P_2 \oplus \ldots \oplus P_n$, 
we have the following equation reminiscent of (\ref{fjoin_partition}):
\begin{equation}
 f^P = f^{P_1} \oplus f^{P_2} \oplus \ldots \oplus f^{P_n}
\end{equation}


Joining a function with itself is not the most interesting construction.
Piecewise functions are useful for their ability to tie together two \emph{different functions}.
If two functions have separate, non-overlapping regions, then our definition is again trivial.


\begin{theorem}
	Given two function $f : U \to S$ and $g : U \to S$. The following identity holds if and only if $A$ and $B$ are disjoint:
	\begin{equation}
		f^A \oplus g^B = (f \fjoin g)^{A \oplus B}
	\end{equation}
\end{theorem}


Notice here the use of $\fjoin$ on the right hand side.
Here we are joining two non-hybrid functions.
Since $A$ and $B$ are disjoint, the problems that arose earlier are not a problem.
Disjointness is still too strong of a condition for us.
The join of two non-disjoint functions may still be a hybrid function 
even if their respective functions do not agree at \emph{all} points.
So long as long as they agree on all points in overlapping regions intersection the functions can be safely joined.


\begin{definition}
	We say that two hybrid functions \textbf{$\boldsymbol{f^A}$ and $\boldsymbol{g^B}$ are compatible} 
	if and only if $f(x) = g(x)$ for all $x \in \text{supp} (A \otimes B)$.
	$f^A \oplus  g^B$ is a hybrid function if and only if $f^A$ and $g^B$ are compatible.
\end{definition}


As with our definition of disjointness, the pointwise product $\otimes$, 
of hybrid sets acts as a hybrid set analog for intersection $\cap$, of sets.
The notion of compatibility generalizes the two cases we have already seen.
$f^A \oplus f^B$ are compatible hybrid functions because $f$ agrees with itself everywhere.
For $A$ and $B$ disjoint, $f^A$ and $g^B$ are compatible since $A \otimes B$ is empty.
Compatibility is not associative.
Consider the following sequence:


\begin{equation}
(f^H \oplus g^H) \oplus g^{\ominus H} = f^H \oplus (g^H \oplus g^{\ominus H}) = f^H \oplus g^\emptyset = f^H
\end{equation}


Although $f^H$ and $g^H$ could be mutually incompatible; 
we can only certain that $f^H \oplus g^H$ is a hybrid relation.
Regardless of their compatibility, when this is joined with $g^{\ominus H}$, the $g$ terms cancel.
What we are left with \emph{is} a hybrid function.
Similarly, reducibility is clearly not preserved by $\hjoin$ as taking $g=f$ gives an intermediate $f^{2H}$, 
which is only reducible if $H=\emptyset$


Irreducible functions can also reduce a hybrid function by an operator.
To aid in this we will introduce some notation for iterated operators.
\begin{definition}
	Let $\op : S \times S \to S$ be an operator on $S$.
	Then, for $n > 0$, $n \in \mathbb{Z}$ we use $\op^n:S \times S \to S$ to denote iterated $\op$.
	So,
	\begin{equation}
		x \op^n y = x \overbrace{\op y \op y \op \ldots \op y}^{n \text{ times}}
	\end{equation}
	If $\op$ has an identity $e_\op$, then we extend $x \op^0 y = e_\op$.
	If $\op$ is invertible, then we use $\op^{-1}$ to denote its inverse and $\op^{-n}$ for iterated $\op^{-1}$.
	Finally, we allow $\op^n$ to be a unary operator, which we define by $\op^n x = e_\op \op^n x$.
\end{definition}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% *-Reducible
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{definition}
	We say that a hybrid relation $f^A = f_1^{A_1} \oplus f_2^{A_2} \oplus \ldots$ over $T \times S$ 
	is $\op$\textbf{-reducible} if $(S, \op)$ is an abelian group 
	or if $(S, \op)$ is an abelian semi-group and $f^A$ is everywhere non-negative.
	If $f^A$ is $\op$-reducible we define its $\op$\textbf{-reduction}, $\mathcal{R}_\op(f^A) :  T \to S$ 
	as a (non-hybrid) function given by:
	\begin{equation}
		\left( \mathcal{R}_\op (f^A) \right)\;(x) = \op^{A_1(x)} f_1(x) \op^{A_2(x)} f_2(x) \op \ldots 
	\end{equation}
\end{definition}


If $f^A$ is reducible then it is $\op$-reducible.


\subsection{Example: \emph{Sign function}}

One would typically write the sign function out as a piecewise function over 3 regions of the extended real line: 
$(-\infty, 0)$, $\{ 0 \}$, and $(0, \infty)$.
Written out as a hybrid function, this would be
\begin{equation}
	\text{sign} = -1^{(-\infty, 0)} \hjoin 0^{\{0\}} \hjoin 1^{(0, \infty)}
\end{equation}
Alternatively, one could also use the equivalent:
\begin{equation}
	\text{sign} = \mathcal{R}_+ \left( -1^{(-\infty, 0]} \oplus 1^{[0, \infty)} \right)
\end{equation}

Going from 3 regions to 2 may seem a small step.
However, consider two piecewise functions with $n$ and $m$ regions respectively.
Taking the sum of these two functions would lead to a new piecewise function with $n\cdot m$ regions.
We will show that $\op$-reductions can allow us to reduce this to only a linear increase!


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Piecewise 1
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Example: \emph{Piecewise functions on generalized partitions}} 
Let $A_1 = [0,a)$, $A_2 = [0,1] \setminus A_1$, $B_1 = [0,b)$ and $B_2 = [0,1] \setminus B_1$.
As well as piecewise functions $f$ and $g$ given as:
\begin{equation*}
	f(x) = f_1^{A_1} \oplus f_2^{A_2}
		= \begin{cases}
			f_1(x) & x \in A_1 \\
			f_2(x) & x \in A_2
		\end{cases}
	\;\;\;\;\; \text{and} \;\;\;\;\;
	g(x) = g_1^{B_1} \oplus g_2^{B_2}
		= \begin{cases}
			g_1(x) & x \in B_1 \\
			g_2(x) & x \in B_2
		\end{cases}
\end{equation*}

To compute $(f+g)$, the naive simplication would be to take the pairwise intersection of regions.
\begin{equation}
	(f+g)(x) = (f_1 + g_1)^{A_1 \cap B_1} 
		\oplus (f_1 + g_2)^{A_1 \cap B_2} 
		\oplus (f_2 + g_1)^{A_2 \cap B_1}
		\oplus (f_2 + g_2)^{A_2 \cap B_2}
\end{equation}

However, we can alternatively partition $[0,1]$ into the generalized partition $A_1$, $B_1 \ominus A_1$, $B_2$.
Observe that $B_1 = (B_1 \ominus A_1) \oplus A_1$ and $A_2 = (B_1 \ominus A_1) \oplus B_2$.
Thus we can represent $f$ and $g$ with a common partition by:
\begin{align}
	f &=  f_1^{A_1} \;\oplus\; f_2^{(B_1 \ominus A_1) \oplus B_2}
		\;=\; f_1^{A_1} \;\oplus\; f_2^{B_1 \ominus A_1} \;\oplus\; f_2^{B_2} \\
	g &= g_1^{A_1 \oplus (B_1 \;\ominus\; A_1)} \;\oplus\; g_2^{B_2}
		\;=\; g_1^{A_1} \;\oplus\; g_1^{B_1 \;\ominus\; A_1} \;\oplus\; g_2^{B_2}
\end{align}

Then we write:

\begin{equation}
	(f+g)(x) = \mathcal{R}_+ \left( (f_1 + g_1)^{A_1} 
			\oplus (f_2 + g_1)^{B_1 \ominus A_1} 
			\oplus (f_2 + g_2)^{B_2} \right)
\end{equation}


This equation holds regardless of the relative ordering of $a$ and $b$.
Suppose $x \in A_1 \cap B_1$
Then we have $A_1(x)= 1$ and $(B_1 \ominus A_1)(x) = B_2(x) = 0$.
And so $(f+g)(x) = (f_1 + g_1)(x)$.
Similarly, if $x \in B_1 \cap A_2$ or $x \in A_2 \cap B_2$ then 
only $(B_1 \ominus A_1)(x)$ or $B_2(x)$ will respectively be non-zero.
However, if $x \in B_2 \cap A_1$ then we have $A_1(x) = 1$, $(B_1 \ominus A_1)(x) = -1$ and $B_2(x) = 1$.
Simplifying this expression yields:
\begin{equation}
	(f+g) \;=\; +^1 (f_1 + g_1) +^{-1} (f_2 + g_1) +^1 (f_2 + g_2) \;=\; (f_1 + g_2)
\end{equation}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Refinement
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Even though in this example only three regions can simultaneously exist 
(either $A_1 \cap B_2$ or $A_2 \cap B_1$ will be empty)
 this technique does not depend on it.
$A_1$ and $B_1$ could be arbitrary subsets.
We will even extend this to any generalized partition.
First we will formalize some ideas we have already seen.


\begin{definition}
	A \textbf{refinement} of a generalized partition $P = \{P_i\}_{i \in I}$ is another generalized partition
	$Q = \{Q_j \}_{j \in J}$ such that 
	\begin{equation}
		\bigoplus_{j \in J} Q_j = \bigoplus_{i \in I} P_i
	\end{equation}
	and for every $P_i$ in $P$ there is a sequence $\{ Q_{i_k} \}_{i_k \in I_k}$, $I_k \subseteq J$ such that 
	\begin{equation}
		P_i = \bigoplus_{i_k \in I_k} Q_{i_k}
	\end{equation}
	A \textbf{common refinement} for a set of generalized partitions is a generalized partition which is a 
	refinement of every partition in the set. 
	A refinement is \textbf{strict} if $\text{supp}(Q) = \text{supp}(P)$.
\end{definition}


In our previous example we used $\{ A_1, B_1 \ominus A_1, B_2 \}$ which was a common refinement of both
$\{ A_1, A_2 \}$ and $\{ B_1, B_2 \}$.
Additionally, it also had the nice feature that its pointwise sum was also $[0,1]$.
This however is not required in the above definition; for example the hybrid set $\hset{[0,1]^1}$ is refined by
$\hset{ [-1,0)^{-1}, (1,2]^{-1}, [-1,2]^1 }$.
However, this refinement is not strict as they do not have the same support.
\todo[inline]{ but it is also refined by $\hset{ [0,1]^1, [1,2]^1, [2,3]^1, \ldots }$ ?!?!}


We can now formally phrase our problem.
Let $A=\{ A_i \}_{i \in [n]}$ and $B=\{ B_j \}_{j \in [m]}$ be two generalized partitions of a hybrid set $U$ 
(where $[n] = \{ 1, \ldots, n \}$ for $n \in \mathbb{N}$).
We wish to find a generalized partition $C$  of $U$ which is a \emph{common}, \emph{strict} refinement of $A$ and $B$
and has minimal cardinality.
This restriction on the cardinality is to minimize the number of terms that appear.
These conditions can be summarized into the following system of $n+m+1$ simultaneous equations:
\begin{equation}
	U = \bigoplus_i C_i
\end{equation}
\begin{equation}
	\forall i \in [n] : A_i = \bigoplus_j  a_{i,j} C_j
\end{equation}
\begin{equation}
	\forall j \in [m] : B_j = \bigoplus_i b_{i,j} C_i
\end{equation}
for some integers $a_{i,j}$ and $b_{i,j}$.
Since we know that $A$ and $B$ are each partitions of $U$, only $n+m-1$ can be independent.
If there are additional dependencies betwen $A$ and $B$ then this can be even lower.
Expressed as a linear system we have:


\begin{equation}
	M \cdot 
		\begin{pmatrix}
			C_1 	\\
			\vdots 	\\
			C_{n+m-1}
		\end{pmatrix}
	=
		\begin{pmatrix}
			U 		\\[-0.5em] 
			A_1 	\\[-0.5em] 
			\vdots 	\\[-0.5em] 
			A_{n-1}	\\[-0.5em] 
			B_1 	\\[-0.5em] 
			\vdots 	\\[-0.5em] 
			B_{m-1}
		\end{pmatrix}
	\;\;\;\;\;\;\text{ where }\;\;
	M = \begin{pmatrix}
			1			& 1			& \cdots 	& 1 					\\[-0.5em]
			a_{1,1}		& a_{1,2}	& \cdots 	& a_{1, n+m-1} 		\\[-0.5em]
			\vdots 		&			&			& \vdots 			\\[-0.5em]
			a_{n-1,1}	& a_{n-1, 2}	& \cdots 	& a_{n-1, n+m-1} 	\\[-0.5em]
			b_{1,1} 		& b_{1,2} 	& \cdots 	& b_{1, n+m-1}		\\[-0.5em]
			\vdots 		& 			&			& \vdots 			\\[-0.5em]
			b_{m-1,1} 	& b_{m-1,2}	& \cdots 	& b_{m-1,n+m-1}
	\end{pmatrix}
\end{equation}


By definition, $M$ is an integer matrix.
But we are actually more interested in its inverse $M^{-1}$ to find values for $C_i$.
If we assume that $M^{-1}$ is also an integer matrix, then the determinant must be $\pm 1$.
Further restricting ourselves to upper triangular matrices we can simply choose $M$ to be all 1's along the diagonal
as well as the top row. 
This is not unique; we could also choose $M$ to be 1s for the whole upper triangle.
Assuming the former, we find the inverse to be:
\begin{equation}
	\begin{pmatrix}
		1 		&\cdots 	&\cdots 	&\cdots 	& 1 		\\[-0.5em]
		0		& 1		& 0 		&\cdots 	& 0 		\\[-0.5em]
		\vdots 	&\ddots 	&\ddots 	&\ddots 	&\vdots 	\\[-0.5em]
		\vdots 	&		&\ddots 	&\ddots 	& 0 		\\[-0.5em]
		0 		&\cdots 	&\cdots 	& 0 		& 1
	\end{pmatrix}^{-1}
	= \; \; \;
	\begin{pmatrix}
		1 		&-1	 	&\cdots 	&\cdots 	& -1		\\[-0.5em]
		0		& 1		& 0 		&\cdots 	& 0 		\\[-0.5em]
		\vdots 	&\ddots 	&\ddots 	&\ddots 	&\vdots 	\\[-0.5em]
		\vdots 	&		&\ddots 	&\ddots 	& 0 		\\[-0.5em]
		0 		&\cdots 	&\cdots 	& 0 		& 1
	\end{pmatrix}
\end{equation}


Thus we find that for the partitions $A = \{ A_i \}_{i \in [n]}$ and $B = \{ B_j \}_{j \in [m]}$ we can \emph{always}
use the strict, common and minimal refinement:
\begin{equation}
	\Big\{ (U \ominus A_1 \ominus \ldots \ominus A_{n-1} \ominus B_1 \ominus \ldots \ominus B_{n-1}), \;\;
	A_1, A_2, \ldots, A_{n-1}, \;\; B_1, B_2, \ldots, B_{m-1}
	\Big\}
\end{equation}
Finally, to generalize our example from earlier, let $f = f_1^{P_1} \oplus f_2^{P_2} \oplus f_n^{P_n}$
and  $g = g_1^{Q_1} \oplus \ldots \oplus g_m^{Q_m}$ be two piecewise functions over a common domain $U$.
We can compute $f \op g$ by:
\begin{align}
f \op g = \; \mathcal{R}_\op  \; & \!\!\! \left( \,
		\hset{ (f_1 \op g_m)^{P_1} } 
		\oplus \ldots \oplus 
		\hset{ (f_{n-1} \op g_m)^{P_{n-1}}} \right. \notag \\
	\oplus & 
		\hset{ (f_n \op g_1)^{Q_1} } 
		\oplus \ldots \oplus 
		\hset{ (f_n \op g_{m-1})^{Q_{m-1}}} \notag \\
	\oplus & \left. 
		\hset{ (f_n \op g_n)^{
			U \ominus (P_1 \oplus \ldots \oplus Q_{n-1} \oplus Q_1 \oplus \ldots \oplus Q_{m-1})}
		}
	\; \right)
\end{align}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% PSEUDO-FUNCTIONS
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Pseudo-functions}

One last detail remains to be settled, the sub-functions $f_i$ and $g_j$ may not be defined outside of 
$P_i$ and $Q_j$ respectively.
We have written $(f_1 \op g_m)^P_1$ but it may be that for some point $x \in P_1$, we have $g_m(x) = \infty$.
Although this point may eventually be cancelled out later symbollically, we enter fuzzy territory.
To resolve this, we use a lambda-lifting trick to have a hybrid relation over the domain and \emph{the function itself}
rather than the domain and the image implied by the function.


\begin{definition}
	Using the same notation as in our definition from (\ref{hfunc}), we define a pseudo-function $\tilde{f}^A$ as:
	\begin{equation}
 		\tilde{f}^A = \bigoplus_{x \in B} A(x) \hset{(x,f)^1}
	\end{equation}
	That is, $\tilde{f}^A$ is a hybrid relation over $U \times (U \to S)$ as opposed to $U \times S$.
	The evaluation of a pseudo-function is done by mapping $\tilde{f}^A$ back down to $f^A$.
\end{definition}

Properties of pseudo-functions


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Piecewise 2
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Example: \emph{Piecewise functions revisited}}
Repeat piece-wise function example with unsafe points (1 page)
\begin{equation}
(2-x^2)^{[-1,1]} \hjoin \left( \frac{1}{x^2} \right)^{\mathbb{R} \ominus [1,1]}
\end{equation}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Convolution
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Example: \emph{Convolution}}

\todo[inline]{Not sure if this is better suited here or in integration. Doesn't really build off of integration.}

\begin{definition}
	The \textbf{convolution} $*$, of two functions $F$ and $G$ is defined as:
	\begin{equation}
		(F*G)(t) = \int_{-\infty}^\infty F(t) \;G(t - \tau) \; d\tau
	\end{equation}
\end{definition}

Is often visualized by graphically flipping one function and sliding it across the other as seen in Figure \ref{convolution}.

\begin{figure}[h]
\label{convolution}
\caption[Convolution of box signal with itself]{The convolution of the box signal 
$f(t)=g(t)=\left( 0^\oiOpOp{-\infty,-0.5} \oplus 1^\oiClCl{-0.5,0.5} \oplus 0^\oiOpOp{0.5,\infty} \right)$ with itself.
\emph{(from wikipedia; need to create new versions)}}
\centering
\includegraphics[scale=0.6]{diagrams/conv1}
\includegraphics[scale=0.6]{diagrams/conv2}
\includegraphics[scale=0.6]{diagrams/conv3}
\end{figure}

Has applications in signal processing

Frequently used in image processing

  Gaussian blurring result of convolving a function with the Gaussian function:
\begin{equation}
	f(x) = a \; \text{exp} \left( - \frac{(x-b)^2}{2c^2} \right)
\end{equation}

In statistics a weighted moving average is a convolution

We are interested in \emph{Symbolic Linear Convolution} (of piecewise continuous functions)

First we consider the convolution of ``one piece'' functions:

\begin{equation}
	F(x)=f^{[a_f,b_f)}(x) = 
		\begin{cases}
			f(x) & a_f \leq x < b_f \\
			0 & \text{otherwise}
		\end{cases}
\end{equation}

\begin{equation}
	G(x)=g^{[a_g,b_g)}(x) = 
		\begin{cases}
			g(x) & a_g \leq x < b_g \\
			0 & \text{otherwise}
		\end{cases}
\end{equation}

Generally we assume that $b_f - a_f \leq b_g - a_g$, ($f$ is shorter)

If this is not the case, convolution is commutative so we simply rearrange: $F * G = G * F$

\begin{align}
	(F*G)(t) 
	&= \int_{-\infty}^\infty F(\tau)\; G(t-\tau) \; d\tau \notag \\
	&= \int_{a_f}^{b_f} f(\tau) \; G(t-\tau) \; d\tau \notag \\
	&= 	\begin{cases}
			\int_{a_f}^{x-a_g} f(\tau) \; g(t-\tau) \; d\tau 	& (a_f+a_g) \leq t < (b_f+a_g) \\
			\int_{a_f}^{b_f} f(\tau) \; g(t-\tau) \; d\tau		& (b_f+a_g) \leq t < (a_f+b_g) \\
			\int_{x-b_g}^{b_f} f(\tau) \; g(t-\tau) \; d\tau	& (a_f+b_g) \leq t < (b_f+b_g) \\
			0										& \text{otherwise}
		\end{cases}
\end{align}


This is the way it's typically done.

With hybrid functions we can ???


\newpage